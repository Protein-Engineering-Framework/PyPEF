{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niklas E. Siedhoff<sup><em>1,§</em></sup>, Alexander-Maurice Illig<sup><em>1,§</em></sup>, Ulrich Schwaneberg<sup><em>1,2</em></sup>, Mehdi D. Davari<sup><em>1,*</em></sup>, <br>\n",
    "PyPEF – an Integrated Framework for Data-driven Protein Engineering, <em>Journal of Chemical Information and Modeling</em> (2021) <br>\n",
    "<sup><em>1</em></sup><sub>Institute of Biotechnology, RWTH Aachen University, Worringer Weg 3, 52074 Aachen, Germany</sub> <br>\n",
    "<sup><em>2</em></sup><sub>DWI-Leibniz Institute for Interactive Materials, Forckenbeckstraße 50, 52074 Aachen, Germany</sub> <br>\n",
    "<sup><em>*</em></sup><sub>Corresponding author</sub> <br>\n",
    "<sup><em>§</em></sup><sub>Equal contribution</sub> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Aminoacid_Index import Database\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as clst\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating clusters\n",
    "\n",
    "In order to generate cluster the AAindex database using correlation coefficients, amino acid indices which do not contain information for all 20 natural amino acids have to be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessions = [k for k, v in Database.items() if v.is_complete]\n",
    "accessions_data = np.array([Database[accession].values for accession in accessions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Cluster_Member(data, holdout_index, threshold):\n",
    "    \n",
    "    # first cluster member is houldout\n",
    "    cluster_data = [data[holdout_index]]\n",
    "    cluster_indices = [holdout_index]\n",
    "\n",
    "    # iterate N times over dataset of length N\n",
    "    for iteration in range(len(data)):\n",
    "        \n",
    "        # d is data of entry with index\n",
    "        for index, d in enumerate(data):\n",
    "            \n",
    "            # ensure that entry is not member of cluster\n",
    "            if index not in cluster_indices:\n",
    "                \n",
    "                # determine correlation of entry with each cluster member\n",
    "                for d0 in cluster_data:\n",
    "                    correlation = np.corrcoef(d0, d)[0,1]\n",
    "                    \n",
    "                    # if correlation is larger than threshold, add to cluster\n",
    "                    if correlation > threshold:\n",
    "                        cluster_indices.append(index)\n",
    "                        cluster_data.append(d)\n",
    "                        break\n",
    "\n",
    "    directory_name = \"cc_\" + str(threshold)\n",
    "    # save cluster data and indices of members in numpy array\n",
    "    name = str(holdout_index) + '_data.npy'\n",
    "    np.save(os.path.join(directory_name, name), cluster_data)\n",
    "\n",
    "    name = str(holdout_index) + '_indices.npy'\n",
    "    np.save(os.path.join(directory_name, name), cluster_indices)\n",
    "\n",
    "    return cluster_indices\n",
    "\n",
    "\n",
    "def Correlation_Clustering(data, threshold):\n",
    "    \n",
    "    # make directory for storing numpy arrays\n",
    "    directory_name = \"cc_\" + str(threshold)\n",
    "    try:\n",
    "        os.mkdir(directory_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    number_of_complete_entries = data.shape[0]\n",
    "    \n",
    "    cluster_indices = []\n",
    "    indices_assigned_to_cluster = []\n",
    "    \n",
    "\n",
    "    for holdout_index in tqdm(np.arange(number_of_complete_entries)):\n",
    "        \n",
    "        # check for every complete amino acid index, if it is already member of a cluster\n",
    "        # if not, find cluster\n",
    "        if holdout_index not in indices_assigned_to_cluster:\n",
    "            clusters = Find_Cluster_Member(data, holdout_index, threshold)\n",
    "            indices_assigned_to_cluster += clusters\n",
    "            cluster_indices.append(clusters)\n",
    "            \n",
    "    # save indices of cluster member\n",
    "    name = \"cc_\" + str(threshold) + \"_results.npy\"\n",
    "    np.save(os.path.join(directory_name, name), clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the clustering by specifying a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correlation_Clustering(accessions_data, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the obtained clusters\n",
    "\n",
    "In order to identify which properties have been clustered together, we look at the data description of the members of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_Words(words):\n",
    "    counts = dict()\n",
    "\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return {k: v for k, v in sorted(counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "def Anaylze_Clusters(directory_name, accessions, minimum_population):    \n",
    "    clusters = []\n",
    "    for file in os.listdir(directory_name):\n",
    "        if file.endswith(\"_indices.npy\"):\n",
    "\n",
    "            accessions_of_cluster_members = []\n",
    "            data_description_of_cluster_members = []\n",
    "            \n",
    "            accession_indices = np.load(os.path.join(directory_name, file))\n",
    "            \n",
    "            if len(accession_indices) >= minimum_population:\n",
    "                for accession_index in accession_indices:\n",
    "                    accession = accessions[accession_index]\n",
    "                    accessions_of_cluster_members.append(accession)\n",
    "\n",
    "                    data_description = Database[accession].data_description\n",
    "                    data_description_of_cluster_members.append(data_description)\n",
    "\n",
    "                clusters.append([file, accessions_of_cluster_members, data_description_of_cluster_members])\n",
    "            \n",
    "    return clusters\n",
    "\n",
    "def Find_Heading(directory_name, accessions, minimum_population=7):\n",
    "    \n",
    "    clusters = Anaylze_Clusters(directory_name, accessions, minimum_population)\n",
    "    for file, _, descriptions in clusters:\n",
    "        descripts = []\n",
    "        for desc in descriptions:\n",
    "            print(desc)\n",
    "            descripts += desc.rstrip().split(' ')\n",
    "        # print(file, Count_Words(descripts), 2*'\\n')\n",
    "        print(file, 2*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Find_Heading(\"cc_\" + str(threshold), accessions, minimum_population=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = {\"120\":\"Partition energies\", \"26\":\"Polarity\", \"32\":\"Size\",\n",
    "            \"47\":\"Composition\", \"69\":\"Alpha helix\", \"71\":\"Beta structure\", \"66\":\"Surface area\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rearange_Correlation_Matrix(correlation_matrix):\n",
    "    \n",
    "    distances = clst.distance.pdist(correlation_matrix)\n",
    "    linkage = clst.linkage(distances, method='complete')\n",
    "    threshold = 0.5*np.max(distances)\n",
    "    indices_sorted = clst.fcluster(linkage, threshold, criterion='distance')\n",
    "    indices = np.argsort(indices_sorted)\n",
    "\n",
    "    return (correlation_matrix[indices, :][:, indices], indices)\n",
    "\n",
    "def Visualize_Correlation_Matrix(data, indices, accessions, save=False):\n",
    "    \n",
    "    correlation_matrix, indices = Rearange_Correlation_Matrix(np.corrcoef(data))\n",
    "    labels = np.array(accessions)[indices]\n",
    "    \n",
    "    cbarlabel = 'Correlation'\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(correlation_matrix, cmap='Blues', vmin=-1, vmax=1)\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    ax.set_xticks(np.arange(correlation_matrix.shape[0]))\n",
    "    ax.set_yticks(np.arange(correlation_matrix.shape[1]))\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=False, labelbottom=True)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12, 10)\n",
    "    if save:\n",
    "        fig.savefig('Mat.png', dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_name = \"cc_0.95\"\n",
    "for k,v in headings.items():\n",
    "    data_file = os.path.join(directory_name, k +\"_data.npy\")\n",
    "    data = np.load(data_file)\n",
    "    \n",
    "    indices_file = os.path.join(directory_name, k +\"_indices.npy\")\n",
    "    indices = np.load(indices_file)\n",
    "    \n",
    "    print(v)\n",
    "    Visualize_Correlation_Matrix(data, indices, np.array(accessions)[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating compatible textfiles\n",
    "\n",
    "After generating the clusters, textfiles similiar to those from the AAindex database are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_PCA(data):\n",
    "    \n",
    "    pca = PCA(n_components=1)\n",
    "    X = pca.fit_transform(Normalizer().transform(data.T))\n",
    "    \n",
    "    return X.flatten()\n",
    "\n",
    "def Generate_Text_File(cluster, headings, directory_name):\n",
    "    \n",
    "    idx = cluster[0].split('_')[0]\n",
    "    file = os.path.join(directory_name, idx + '_data.npy')\n",
    "    \n",
    "    data = np.load(file)\n",
    "    data_pca = Apply_PCA(data)\n",
    "    \n",
    "    rows = np.split(data_pca, 2)\n",
    "    upper_borders = [7 + 8*i for i in range(10)]    \n",
    "\n",
    "    heading = headings[idx]\n",
    "    members = cluster[1]\n",
    "    \n",
    "    H = \"H \" + heading + \"\\n\" \n",
    "    D = \"D \" + \" \".join(members) + \"\\n\"\n",
    "    I = \"I    A/L     R/K     N/M     D/F     C/P     Q/S     E/T     G/W     H/Y     I/V\\n\"\n",
    "    \n",
    "    filename = heading + \".txt\"\n",
    "    \n",
    "    with open(filename, \"w\") as f:    \n",
    "        f.write(H)\n",
    "        f.write(D)\n",
    "        f.write(I)\n",
    "        \n",
    "        for row in rows:\n",
    "            line = [\" \" for i in range(len(I)-1)]\n",
    "            line.append(\"\\n\")\n",
    "\n",
    "            for val, border in zip(row, upper_borders):    \n",
    "                val = \"%.3f\"%(val)\n",
    "\n",
    "                for idx, char in enumerate(val[::-1]):\n",
    "                    pos = border - idx\n",
    "                    line[pos] = char\n",
    "\n",
    "            f.write(\"\".join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = Anaylze_Clusters(\"cc_\" + str(threshold), accessions, minimum_population=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    Generate_Text_File(cluster, headings, directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_string = list(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "\n",
    "directory_name = \"cc_0.95\"\n",
    "for k,v in headings.items():\n",
    "    data_file = os.path.join(directory_name, k +\"_data.npy\")\n",
    "    data = np.load(data_file)\n",
    "    \n",
    "    indices_file = os.path.join(directory_name, k +\"_indices.npy\")\n",
    "    indices = np.load(indices_file)\n",
    "    \n",
    "    pca_data = Apply_PCA(data)\n",
    "    argsort = np.argsort(pca_data)\n",
    "    pca_data = pca_data[argsort]\n",
    "    annotations = np.array(x_string)[argsort]\n",
    "    \n",
    "    x_top = []\n",
    "    text_top = []\n",
    "    \n",
    "    x_bottom = []\n",
    "    text_bottom = []\n",
    "    for i, (val, ann) in enumerate(zip(pca_data, annotations)):\n",
    "        if i%2:\n",
    "            x_top.append(val)\n",
    "            text_top.append(ann)\n",
    "        else:\n",
    "            x_bottom.append(val)\n",
    "            text_bottom.append(ann)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=x_top, y=np.zeros(10),\n",
    "                             mode='markers+text', marker_size=10,\n",
    "                             marker_symbol='triangle-up',\n",
    "                             text=text_top, textposition=\"top center\"\n",
    "                            ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=x_bottom, y=np.zeros(10),\n",
    "                         mode='markers+text', marker_size=10, marker_symbol='triangle-down',\n",
    "                         text=text_bottom, textposition=\"bottom center\"\n",
    "                        ))\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=False, \n",
    "                     zeroline=True, zerolinecolor='black', zerolinewidth=3,\n",
    "                     showticklabels=False)\n",
    "    fig.update_layout(height=250, plot_bgcolor='white', title=v, xaxis_title=\"PC 1\")\n",
    "    fig.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(annotations, pca_data)\n",
    "    plt.plot(annotations, pca_data, linestyle='--')\n",
    "    plt.xlabel('Amino acid')\n",
    "    plt.ylabel('PC 1')\n",
    "    plt.title(v)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = Anaylze_Clusters(\"cc_\" + str(threshold), accessions, minimum_population=6)\n",
    "Xlabel = []\n",
    "X = []\n",
    "for i, cluster in enumerate(clusters):\n",
    "    for accession_number in cluster[1]:\n",
    "        vals = Database[accession_number].values\n",
    "        X.append((np.array(vals) - np.mean(vals))/np.std(vals, ddof=1))\n",
    "        Xlabel.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X = np.array(X)\n",
    "X_pca = pca.fit_transform(Normalizer().transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_structured = []\n",
    "\n",
    "i0 = 0\n",
    "temp = []\n",
    "for i, x in zip(Xlabel, X_pca):\n",
    "    if i == i0:\n",
    "        temp.append(x)\n",
    "    else:\n",
    "        X_pca_structured.append(np.array(temp))\n",
    "        temp = [x]\n",
    "        i0 = i\n",
    "# X_pca_structured = np.array(X_pca_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=12)\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('legend', fontsize=11)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "for x, h in zip(X_pca_structured, headings.values()):\n",
    "    plt.scatter(x[:,0], x[:,1], label=h, s=25, edgecolor='black', linewidth=0.4)\n",
    "# plt.legend(ncol=2, bbox_to_anchor=[0.5, -0.35], loc='center')\n",
    "plt.legend(ncol=1, loc=1)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.ylim(-0.9, 1.2)\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('Clustering.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Done!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
